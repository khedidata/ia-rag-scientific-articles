# AI Assistant (RAG) â€“ arXiv Scientific Documentation

Un assistant **RAG (Retrieval-Augmented Generation)** conÃ§u pour interroger automatiquement les abstracts [arXiv](https://arxiv.org/) en Computer Science.  

Lâ€™utilisateur peut poser des questions en langage naturel, et le systÃ¨me gÃ©nÃ¨re des rÃ©ponses :  

- **StructurÃ©es** : rÃ©sumÃ© concis suivi de dÃ©tails en puces.
- **SourcÃ©es** : chaque Ã©lÃ©ment provient du contexte documentaire rÃ©cupÃ©rÃ©. 
- **Accessibles** : via une interface web minimaliste et intuitive.  

Le projet est dÃ©veloppÃ© en **Python 3.11** et repose sur plusieurs composants modernes :  

- **LangChain** â†’ orchestration des prompts, mÃ©moire conversationnelle et logique RAG.
- **FAISS** â†’ moteur de recherche vectorielle pour indexer et retrouver les abstracts.  
- **OpenAI** â†’ modÃ¨les de langage pour la gÃ©nÃ©ration augmentÃ©e. 
- **FastAPI** â†’ API backend performante servant les rÃ©ponses et lâ€™interface web.  

---

## Project Pipeline

This project follows a structured pipeline of Retrieval-Augmented Generation (RAG) made for scientific articles in computer science (arXiv).

### 1. Data Collection

- **Source** : Automated scraping of articles via the official [arXiv API](https://info.arxiv.org/help/api/).
- **Preprocessing** : Retention of information deemed essential &rarr; Abstract + Metadatas.
- **Post Preprocessing Storage** : Data is stored locally in the `data\`.

### 2. Embeddings & Indexing

- **Model** : The embedding model used is [allenai-specter](https://huggingface.co/allenai/specter), which is very good for arXiv documentation.
- **Vector Store** : Using a FAISS indexing method to vectorized articles.
- **Post Treatment** : Indexed articles saved in `faiss_index\`.

### 3. RAG Pipeline

- **User Query**  
  The user asks a question in natural language through the web interface.
- **Query Expansion (optional)**  
  The query can be reformulated into several variants to improve the retrieval of relevant documents.
- **Retrieval**  
  The different query formulations are used to search for similar abstracts in the vector database (**FAISS**).  
  The results are merged (e.g., with **Reciprocal Rank Fusion**) to keep only the most relevant documents.
- **Context Building**  
  The selected abstracts and metadata are assembled into a **structured context**.
- **Answer Generation (LLM)**  
  The language model (**OpenAI via LangChain**) generates a response:  
  - Short summary in 1â€“2 sentences,  
  - Detailed bullet points for key ideas,  
  - Embedded references (title + arXiv link).  
- **Conversation Memory**  
  The history of questions and answers is stored to maintain context across multiple turns.

### 4. Web Application (FastAPI)

- **Backend**: FastAPI serves the API (`/chat`, `/docs`) and the HTML interface.  
- **Frontend**: a simple `index.html` with a chat-style interface to ask questions and display answers.  
- **Integration**: user queries are sent to the RAG pipeline, and answers are shown directly in the browser.

---

## Project Structure

```bash
â”œâ”€â”€ .dockerignore               # Files and folders excluded from Docker build context  
â”œâ”€â”€ .env                        # Environment variables (API keys, LangSmith config, etc.)  
â”œâ”€â”€ .gitignore                  # Git ignored files and folders  
â”œâ”€â”€ .python-version             # Python version specification (e.g., pyenv/Poetry)  
â”œâ”€â”€ Dockerfile                  # Docker image definition  
â”œâ”€â”€ docker-compose.yml          # Orchestration of the app in Docker  
â”œâ”€â”€ requirements.txt            # Python dependencies  
â”œâ”€â”€ README.md                   # Project documentation 
â”‚
â”œâ”€â”€ app/                        # FastAPI application  
â”‚   â””â”€â”€ app.py                  # API endpoints (serves UI and /chat)  
â”‚
â”œâ”€â”€ chains/                     # LangChain pipelines  
â”‚   â”œâ”€â”€ conversational_qa.py    # Main RAG chain (retrieval + answer generation)  
â”‚   â”œâ”€â”€ prompts.py              # Prompt templates for rephrasing and answering  
â”‚   â”œâ”€â”€ utils.py                # Helper functions for RAG pipelines  
â”‚   â””â”€â”€ __init__.py  
â”‚
â”œâ”€â”€ config.py                   # Global configuration (API keys, settings)  
â”‚
â”œâ”€â”€ constants/                  # Global constants  
â”‚   â”œâ”€â”€ constants.py            # Constant values used across the project  
â”‚   â””â”€â”€ __init__.py  
â”‚
â”œâ”€â”€ data/                       # Local dataset storage  
â”‚   â””â”€â”€ articles.parquet        # Collected and preprocessed arXiv abstracts  
â”‚
â”œâ”€â”€ data_collection/            # Data acquisition pipeline  
â”‚   â”œâ”€â”€ collector.py            # Fetch articles from arXiv API  
â”‚   â”œâ”€â”€ preprocess.py           # Clean and normalize raw data  
â”‚   â””â”€â”€ __init__.py  
â”‚
â”œâ”€â”€ factory/                    # Factory methods / dependency injection  
â”‚   â”œâ”€â”€ factory.py              # Build LangChain components (LLM, retriever, etc.)  
â”‚   â””â”€â”€ __init__.py  
â”‚
â”œâ”€â”€ faiss_index/                # Prebuilt FAISS vector index  
â”‚   â”œâ”€â”€ index.faiss             # FAISS binary index  
â”‚   â””â”€â”€ index.pkl               # Metadata for the index  
â”‚
â”œâ”€â”€ index.html                  # Minimal web chat interface (frontend)  
â”‚
â”œâ”€â”€ ingests/                    # Embeddings & indexing pipeline  
â”‚   â”œâ”€â”€ embeddings.py           # Embedding model setup (sentence-transformers, etc.)  
â”‚   â”œâ”€â”€ indexing.py             # Index creation and persistence (FAISS + metadata)  
â”‚   â””â”€â”€ __init__.py  
â”‚
â”œâ”€â”€ models/                     # Vector store retriever logic  
â”‚   â”œâ”€â”€ vstore_retriever.py     # Custom retriever using FAISS  
â”‚   â””â”€â”€ __init__.py  
â”‚
â””â”€â”€ utils/                      # General utility functions  
    â”œâ”€â”€ functions.py            # Misc helper functions  
    â””â”€â”€ __init__.py  
```


## ðŸ“¦ Installation locale

### PrÃ©requis
- Python â‰¥ 3.11
- [Poetry](https://python-poetry.org/) ou `pip`
- Une clÃ© OpenAI valide (`OPENAI_API_KEY`)

### Ã‰tapes
```bash
git clone https://github.com/monuser/ia_rag_arxiv.git
cd ia_rag_arxiv

# CrÃ©er un venv
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.\.venv\Scripts\activate   # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer lâ€™app
uvicorn app.app:app --reload --port 8000
